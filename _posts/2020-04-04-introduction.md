---
layout: page
title: I’m a researcher at the Centre for the Governance of AI in Oxford. I try to reduce existential risks from AI by improving the corporate governance of AGI labs.
---

 <br>
I'm a Research Fellow at the [Centre for the Governance of AI (GovAI)](https://www.governance.ai/) in Oxford. Before joining GovAI, I was seconded to the UK Cabinet Office to support their work on AI regulation, and interned at DeepMind’s Public Policy team. I also helped found the [Legal Priorities Project](https://www.legalpriorities.org/), where I'm still a Research Affiliate and board member, and worked as a Consultant at KPMG Law. I'm currently wrapping up my PhD in law at Goethe University Frankfurt. I hold a law degree from Heidelberg University and studied economics at the University of Zurich.

![Jonas Schuett](/jonasschuett.jpg "Jonas Schuett")


### Work experience
- **Centre for the Governance of AI** • Research Fellow <br>
2022–present

- **UK Cabinet Office** • Expert Advisor (Artificial Intelligence) <br>
2022

- **DeepMind** • Policy Research and Intelligence Intern <br>
2021

- **Legal Priorities Project** • Research Fellow <br>
2020–2022

- **KPMG Law** • Consultant <br>
2018–2020

- **White & Case** • Research Assistant <br>
2014–2015, 2018

---

### Education
- **Goethe University Frankfurt** • PhD, Law <br>
2018–present

- **Heidelberg University** • MJur / First State Exam, Law <br>
2012–2018

- **University of Zurich** • Economics <br>
2011–2012

---

### Ongoing research projects
- **Responsible AGI labs** (w/ dozens of co-authors): I'm currently working on a big report on responsible AGI labs. We review current practices ("where we are"), sketch an ideal governance regime ("where we need to be"), and recommend concrete steps labs could take today ("how we get from here to there"). This project is my main priority at the moment.

- **AGI labs need an internal audit function**: I argue that AGI labs should seriously consider setting up an internal audit team. This team would assess the effectiveness of the lab's risk management practices. It would be independent from senior management and report directly to the board of directors.

- **Risk assessment at AGI labs** (w/ [Leonie Koessler](https://www.linkedin.com/in/leonie-koessler-ll-m-kcl-85b71814a/)): We review risk assessment techniques from IEC 31010:2019 and other industries (especially aviation, nuclear, and finance) and discuss how AGI labs could use them.

- **AI ethics boards** (w/ [Anka Reuel](https://www.linkedin.com/in/ankareuel/), [Alexis Carlier](https://www.linkedin.com/in/alexis-carlier-995367170/)): We identify key design choices when setting up an ethics board and discuss how they affect the board’s ability to reduce risks from AI.

- **Board governance at AGI labs** (w/ [Nikhil Mulani](https://www.linkedin.com/in/nmulani/), [John Bridge](https://www.linkedin.com/in/johnmichaelbridge/)): We give an overview of the board’s responsibility for risk oversight under Delaware law. We then discuss how AGI labs could set up a more safety-conscious board of directors and suggest actions that individual board members can take.

---

### Selected publications

- **Defining the scope of AI regulations** (2023) <br>
Jonas Schuett <br>
Law, Innovation and Technology <br>
[DOI](https://doi.org/10.1080/17579961.2023.2184135) • [arXiv](https://arxiv.org/abs/1909.01095)

- **Auditing large language models: A three-layered approach** (2023) <br>
Jakob Mökander, Jonas Schuett, Hannah R. Kirk, Luciano Floridi <br>
Preprint <br>
[arXiv](https://arxiv.org/abs/2302.08500)

- **Risk management in the Artificial Intelligence Act** (2023) <br>
Jonas Schuett <br>
European Journal of Risk Regulation <br>
[DOI](https://doi.org/10.1017/err.2023.1) • [arXiv](https://arxiv.org/abs/2212.03109)

- **Three lines of defense against risks from AI** (2022) <br>
Jonas Schuett <br>
Preprint <br>
[arXiv](https://arxiv.org/abs/2212.08364)

- **Corporate governance of artificial intelligence in the public interest** (2021) <br>
Peter Cihon, Jonas Schuett, Seth D. Baum <br>
Information <br>
[DOI](https://doi.org/10.3390/info12070275)

- **AI certification: Advancing ethical practice by reducing information asymmetries** (2021) <br>
Peter Cihon, Moritz J. Kleinaltenkamp, Jonas Schuett, Seth D. Baum <br>
IEEE Transactions on Technology and Society <br>
[DOI](https://doi.org/10.1109/TTS.2021.3077595) • [arXiv](https://arxiv.org/abs/2105.10356)

---

### Contact
Find me on [Twitter](https://twitter.com/jonasschuett) and [LinkedIn](https://www.linkedin.com/in/jonasschuett). Contact me at [jonas.schuett@governance.ai](mailto:jonas.schuett@governance.ai).

Find my research on [ORCID](https://orcid.org/0000-0001-7154-5049), [Google Scholar](https://scholar.google.com/citations?user=iZXltDgAAAAJ&hl=en&oi=ao), and [SSRN](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=3705327).
