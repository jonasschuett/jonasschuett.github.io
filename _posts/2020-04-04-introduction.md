---
layout: page
title: I'm a researcher at the Centre for the Governance of AI in Oxford. I try to reduce existential risks from AI by improving the corporate governance of AGI labs.
---

<br>I'm a Research Fellow at the [Centre for the Governance of AI (GovAI)](https://www.governance.ai/). Within the Policy team, I lead the workstream on corporate governance. Before joining GovAI, I was seconded to the UK Cabinet Office to support their work on AI regulation, and interned at DeepMind’s Public Policy team. I also helped found the [Legal Priorities Project](https://www.legalpriorities.org/), where I'm still a Research Affiliate and board member, and worked as a Consultant at KPMG Law. I'm currently wrapping up my PhD in law at Goethe University Frankfurt, supervised by Tobias Troeger. I hold a law degree from Heidelberg University and have studied economics at the University of Zurich.

![Jonas Schuett](/jonasschuett.jpg "Jonas Schuett")


### Work experience

- **Centre for the Governance of AI** • Research Fellow <br>
2022–present

- **UK Cabinet Office** • Expert Advisor (Artificial Intelligence) <br>
2022

- **DeepMind** • Policy Research and Intelligence Intern <br>
2021

- **Legal Priorities Project** • Research Fellow <br>
2020–2022

- **KPMG Law** • Consultant <br>
2018–2020

---

### Education

- **Goethe University Frankfurt** • PhD, Law <br>
2018–present

- **Heidelberg University** • MJur / First State Exam, Law <br>
2012–2018

- **University of Zurich** • Economics <br>
2011–2012

---

### Current projects
- **Responsible AGI labs**: I've recently started a new research project on responsible AGI labs. This project will likely turn into an "intellectual megaproject" with dozens of co-authors. We plan to sketch an ideal governance regime for AGI labs ("where we need to be"), review current practices ("where we are"), and recommend concrete steps labs could take today ("how we get from here to there"). This is my main priority at the moment.

- **AGI labs need an internal audit function**: I argue that AGI labs should seriously consider setting up an internal audit team. This team would assess the effectiveness of the lab's risk management practices. It would be independent from senior management and report directly to the board of directors.

- **Risk assessment at AGI labs** (w/ [Leonie Koessler](https://www.linkedin.com/in/leonie-koessler-ll-m-kcl-85b71814a/)): We review risk assessment techniques from IEC 31010:2019 and other industries (especially aviation, nuclear, and finance) and discuss how AGI labs could use them.

- **AI ethics boards** (w/ [Anka Reuel](https://www.linkedin.com/in/ankareuel/), [Alexis Carlier](https://www.linkedin.com/in/alexis-carlier-995367170/)): We identify key design choices when setting up an ethics board and discuss how they affect the board’s ability to reduce risks from AI.

- **Board governance at AGI labs** (w/ [Nikhil Mulani](https://www.linkedin.com/in/nmulani/), [John Bridge](https://www.linkedin.com/in/johnmichaelbridge/)): We give an overview of the board’s responsibility for risk oversight under Delaware law. We then discuss how AGI labs could set up a more safety-conscious board of directors and suggest actions that individual board members can take.

---

### Publications

- **Defining the scope of AI regulations** (2023) <br>
Jonas Schuett <br>
Law, Innovation and Technology <br>
[DOI](https://doi.org/10.1080/17579961.2023.2184135) • [arXiv](https://arxiv.org/abs/1909.01095)

- **Auditing large language models: A three-layered approach** (2023) <br>
Jakob Mökander, Jonas Schuett, Hannah R. Kirk, Luciano Floridi <br>
[arXiv](https://arxiv.org/abs/2302.08500)

- **Risk management in the Artificial Intelligence Act** (2023) <br>
Jonas Schuett <br>
European Journal of Risk Regulation <br>
[DOI](https://doi.org/10.1017/err.2023.1) • [arXiv](https://arxiv.org/abs/2212.03109)

- **Three lines of defense against risks from AI** (2022) <br>
Jonas Schuett <br>
[arXiv](https://arxiv.org/abs/2212.08364)

- **Corporate governance of artificial intelligence in the public interest** (2021) <br>
Peter Cihon, Jonas Schuett, Seth D. Baum <br>
Information <br>
[DOI](https://doi.org/10.3390/info12070275)

- **AI certification: Advancing ethical practice by reducing information asymmetries** (2021) <br>
Peter Cihon, Moritz J. Kleinaltenkamp, Jonas Schuett, Seth D. Baum <br>
IEEE Transactions on Technology and Society <br>
[DOI](https://doi.org/10.1109/TTS.2021.3077595) • [arXiv](https://arxiv.org/abs/2105.10356)

---

### Contact

– <img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/brands/twitter.svg" width="20" height="20">
[https://twitter.com/jonasschuett](https://twitter.com/jonasschuett)

– <img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/brands/linkedin.svg" width="20" height="20">
[https://www.linkedin.com/in/jonasschuett](https://www.linkedin.com/in/jonasschuett)

– <img src="https://raw.githubusercontent.com/FortAwesome/Font-Awesome/6.x/svgs/solid/envelope.svg" width="20" height="20">
[jonas.schuett@governance.ai](mailto:jonas.schuett@governance.ai)

Find my research on [ORCID](https://orcid.org/0000-0001-7154-5049), [Google Scholar](https://scholar.google.com/citations?user=iZXltDgAAAAJ&hl=en&oi=ao), and [SSRN](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=3705327).
