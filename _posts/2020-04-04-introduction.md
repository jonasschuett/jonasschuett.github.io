---
layout: page
---


[About](#about) &nbsp;&nbsp; [Research](#research) &nbsp;&nbsp; [Advising](#advising) &nbsp;&nbsp; [Publications](#publications)


![Jonas Schuett](/jonasschuett.jpg)

# About

<p class="lead">AI governance researcher and policy advisor. Helping governments and AI companies to manage emerging risks from AI.</p>

I'm a Senior Research Fellow at the [Centre for the Governance of AI (GovAI)](https://www.governance.ai/), a nonprofit organization based in Oxford.

Before joining GovAI, I was seconded to the UK Cabinet Office and interned at Google DeepMind‘s Public Policy Team. I also helped found the [Institute for Law and AI (LawAI)](https://law-ai.org/), where I‘m still a Non-Executive Board Member.

I’m currently wrapping up my PhD in law at Goethe University Frankfurt. I hold a law degree from Heidelberg University and have studied economics at the University of Zurich.

I live in Berlin, but regularly visit Oxford, London, and Washington, DC. Outside work, I enjoy the finer things in life: from specialty coffee and delicious vegan food to contemporary art and the opera. I‘m engaged to my high school sweetheart. We have the best dog in the world.

<i class="fa-brands fa-twitter fa-fw" style="color: #a4acb4"></i> [Twitter](https://twitter.com/jonasschuett) &nbsp;&nbsp; <i class="fa-brands fa-linkedin fa-fw" style="color: #a4acb4"></i> [LinkedIn](https://www.linkedin.com/in/jonasschuett) &nbsp;&nbsp; <i class="fa-solid fa-envelope fa-fw" style="color: #a4acb4"></i> [Email](mailto:jonas.schuett@governance.ai)

---

# Research

My research is aimed at reducing emerging risks from AI.

### Research interests

- **Risk management.** It becomes increasingly clear that the development and deployment of frontier AI systems poses severe risks to society. I study how these risks can be measured and reduced to an acceptable level.

- **Regulation.** Although self-governance plays an important role in reducing emerging risks from AI, we will eventually need frontier AI regulation. I‘m working on several research projects intended to inform the design of a regulatory regime for frontier AI models, especially in the UK and US.

- **Corporate governance.** As frontier AI developers transition from startups to more mature companies, they need to improve their corporate governance. I‘m particularly interested in ways to improve their risk governance.

### Ongoing research projects

**From principles to rules: A regulatory approach for frontier AI** <br>
Jonas Schuett, Markus Anderljung, Leonie Koessler, Alexis Carlier, Ben Garfinkel

**How to estimate the impact and likelihood of risks from AI** <br>
Jonas Schuett, Caroline Baumoehl, Malcolm Murray, Leonie Koessler

**Estimating risks from LLM: A Delphi study** <br>
Malcolm Murray, Noemi Dreksler, Jonas Schuett, Ben Garfinkel, Markus Anderljung

**Criteria for evaluating frontier AI safety policies** <br>
Jide Alaga, Jonas Schuett

**Safety cases for frontier AI** <br>
Marie Buhl, Gaurav Sett, Leonie Koessler, Jonas Schuett

**How to assess the effectiveness of safeguards** <br>
Patrick Levermore, Jonas Schuett

---

# Advising

I regularly advise governments and leading AI companies on various AI policy issues.

### Governments

In the UK, I‘m currently helping the AI Safety Institute (AISI) with a project on safety cases. I have also supported work by the Department for Science, Innovation and Technology (DSIT) on AI risk assessments and best practices in AI safety. Before that, I was seconded to the Cabinet Office to work on AI regulation.

In the US, I mainly try to support the National Institute for Standards and Technology (NIST). I‘m part of the AI Safety Institute Consortium and regularly comment on drafts and requests for information.

### AI companies

I frequently advise leading AI companies on risk management and safety practices. Since many GovAI alumni have joined companies like OpenAI, Google DeepMind, and Anthropic, we have an unusual network.

---

# Publications

**2024**

**From principles to rules: A regulatory approach for frontier AI** <br>
Jonas Schuett, Markus Anderljung, Alexis Carlier, Leonie Koessler, Ben Garfinkel <br>
*The Oxford Handbook on the Foundations and Regulation of Generative AI (forthcoming)* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2407.07300)

**Risk thresholds for frontier AI** <br>
Leonie Koessler, Jonas Schuett, Markus Anderljung <br>
*arXiv preprint arXiv:2406.14713* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2406.14713)

**How to design an AI ethics board** <br>
Jonas Schuett, Anka Reuel, Alexis Carlier <br>
*AI and Ethics* <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.1007/s43681-023-00409-y)

**2023**

**Towards publicly accountable frontier LLMs: Building an external scrutiny ecosystem under the ASPIRE framework** <br>
Markus Anderljung, Everett T. Smith, Joe O'Brien, Lisa Soder, Benjamin Bucknall, Emma Bluemke, Jonas Schuett, Robert Trager, Lacey Strahm, Rumman Chowdhury <br>
*arXiv preprint arXiv:2311.14711* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2311.14711)

**Three lines of defense against risks from AI** <br>
Jonas Schuett <br>
*AI & Society* <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.1007/s00146-023-01811-0)

**Coordinated pausing: An evaluation-based coordination scheme for frontier AI developers** <br>
Jide Alaga, Jonas Schuett <br>
*arXiv preprint arXiv:2310.00374* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2310.00374)

**Open-sourcing highly capable foundation models: An evaluation of risks, benefits, and alternative methods for pursuing open-source objectives** <br>
Elizabeth Seger, Noemi Dreksler, Richard Moulange, Emily Dardaman, Jonas Schuett, K. Wei, Christoph Winter, Mackenzie Arnold, Seán Ó hÉigeartaigh, Anton Korinek, Markus Anderljung, Ben Bucknall, Alan Chan, Eoghan Stafford, Leonie Koessler, Aviv Ovadya, Ben Garfinkel, Emma Bluemke, Michael Aird, Patrick Levermore, Julian Hazell, Abhishek Gupta <br>
*arXiv preprint arXiv:2311.09227* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2311.09227)

**Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries** <br>
Leonie Koessler, Jonas Schuett <br>
*arXiv preprint arXiv:2307.08823* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2307.08823)

**Frontier AI regulation: Managing emerging risks to public safety** <br>
Markus Anderljung, Joslyn Barnhart, Anton Korinek, Jade Leung, Cullen O'Keefe, Jess Whittlestone, Shahar Avin, Miles Brundage, Justin Bullock, Duncan Cass-Beggs, Ben Chang, Tantum Collins, Tim Fist, Gillian Hadfield, Alan Hayes, Lewis Ho, Sara Hooker, Eric Horvitz, Noam Kolt, Jonas Schuett, Yonadav Shavit, Divya Siddarth, Robert Trager, Kevin Wolf <br>
*arXiv preprint arXiv:2307.03718* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2307.03718)

**AGI labs need an internal audit function** <br>
Jonas Schuett <br>
*arXiv preprint arXiv:2305.17038* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2305.17038)

**Towards best practices in AGI safety and governance: A survey of expert opinion** <br>
Jonas Schuett, Noemi Dreksler, Markus Anderljung, David McCaffary, Lennart Heim, Emma Bluemke, Ben Garfinkel <br>
*arXiv preprint arXiv:2305.07153* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2305.07153)

**Defining the scope of AI regulations** <br>
Jonas Schuett <br>
*Law, Innovation and Technology, 15*(1), 60–82 <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.1080/17579961.2023.2184135)

**Auditing large language models: A three-layered approach** <br>
Jakob Mökander, Jonas Schuett, Hannah R. Kirk, Luciano Floridi <br>
*AI and Ethics* <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.1007/s43681-023-00289-2)

**Risk management in the Artificial Intelligence Act** <br>
Jonas Schuett <br>
*European Journal of Risk Regulation*, 1–19 <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.1017/err.2023.1)

**2021**

**AI certification: Advancing ethical practice by reducing information asymmetries** <br>
Peter Cihon, Moritz J. Kleinaltenkamp, Jonas Schuett, Seth D. Baum <br>
*IEEE Transactions on Technology and Society, 2*(4), 200–209 <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.1109/TTS.2021.3077595) &nbsp;&nbsp; <i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [arXiv](https://arxiv.org/pdf/2105.10356)


**Corporate governance of artificial intelligence in the public interest** <br>
Peter Cihon, Jonas Schuett, Seth D. Baum <br>
*Information, 12*(7), 275 <br>
<i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [DOI](https://doi.org/10.3390/info12070275)

---

# Submissions

**2024**

**Comments on NIST’s Draft Profile on Generative AI** <br>
Malcolm Murray, Jonas Schuett, Sam Manning, Alan Chan, Leonie Koessler, Markus Anderljung <br>
*Centre for the Governance of AI* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [PDF](https://cdn.governance.ai/Comments_on_NISTs_Draft_Profile_on_Generative_AI.pdf) &nbsp;&nbsp; <i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [RFI](https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Profile.ipd.pdf)

**Response to the RFI related to NIST's assignments under the Executive Order concerning AI** <br>
Jonas Schuett, Leonie Koessler, Markus Anderljung <br>
*Centre for the Governance of AI* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [PDF](https://cdn.governance.ai/GovAI_Response_to_RFI_Related_to_NIST_Assignments_Under_Executive_Order_Concerning_AI.pdf) &nbsp;&nbsp; <i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [RFI](https://www.federalregister.gov/documents/2023/12/21/2023-28232/request-for-information-rfi-related-to-nists-assignments-under-sections-41-45-and-11-of-the)

**2023**

**National priorities for AI: Response to the OSTP request for information** <br>
Jonas Schuett, Markus Anderljung, Lennart Heim, Elizabeth Seger <br>
*Centre for the Governance of AI* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [PDF](https://cdn.governance.ai/Response_to_the_OSTP_Request_for_Information__National_Priorities_for_Artificial_Intelligence.pdf) &nbsp;&nbsp; <i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [RFI](https://www.whitehouse.gov/wp-content/uploads/2023/05/OSTP-Request-for-Information-National-Priorities-for-Artificial-Intelligence.pdf)

**Response to the NTIA AI accountability policy request for comment** <br>
Everett T. Smith, Jonas Schuett, Markus Anderljung, Lennart Heim <br>
*Centre for the Governance of AI* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [PDF](https://cdn.governance.ai/GovAI_Response_to_the_NTIA_AI_Accountability_Policy_Request_for_Comment.pdf) &nbsp;&nbsp; <i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [RFI](https://www.federalregister.gov/documents/2023/04/13/2023-07776/ai-accountability-policy-request-for-comment)

**2022**

**Submission to the NIST AI Risk Management Framework** <br>
Jonas Schuett, Markus Anderljung <br>
*Centre for the Governance of AI* <br>
<i class="fa-regular fa-file-lines fa-fw" style="color: #a4acb4"></i> [PDF](https://cdn.governance.ai/Comments_on_the_Initial_Draft_of_the_NIST_AI_RMF_-_GovAI.pdf) &nbsp;&nbsp; <i class="fa-solid fa-link fa-fw" style="color: #a4acb4"></i> [RFI](https://www.nist.gov/system/files/documents/2022/03/17/AI-RMF-1stdraft.pdf)

---

[Twitter](https://twitter.com/jonasschuett) • [LinkedIn](https://www.linkedin.com/in/jonasschuett) • [Email](mailto:jonas.schuett@governance.ai) • [ORCID](https://orcid.org/0000-0001-7154-5049) • [Google Scholar](https://scholar.google.com/citations?user=iZXltDgAAAAJ&hl=en&oi=ao) • [SSRN](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=3705327)
