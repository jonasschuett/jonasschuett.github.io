---
layout: page
title: I’m a researcher at the Centre for the Governance of AI (GovAI) in Oxford. I try to reduce risks from advanced AI by helping AGI labs to improve their corporate governance.
---


# About
I’m a Research Fellow at the [Centre for the Governance of AI (GovAI)](https://governance.ai/), a Research Affiliate at the [Legal Priorities Project](https://www.legalpriorities.org/), and a PhD candidate in law at Goethe University Frankfurt.

### Work experience
**Centre for the Governance of AI**, Oxford, UK <br>
Research Fellow <br>
2022–present

**UK Cabinet Office**, London, UK <br>
Expert Advisor (Artificial Intelligence) <br>
2022

**DeepMind**, London, UK <br>
Policy Research and Intelligence Intern <br>
2021

**Legal Priorities Project**, Cambridge, MA, USA <br>
Research Fellow <br>
2020–2022

**KPMG Law**, Frankfurt am Main, Germany <br>
Consultant <br>
2018–2020


### Education
- **Goethe University Frankfurt** <br>
PhD, Law <br>
2018–present

- **Heidelberg University** <br>
MJur / First State Exam, Law <br>
2012–2018

- **University of Zurich** <br>
Economics <br>
2011–2012

---

# Research

### My research interests (“why”)
- Reducing risks from advanced AI
- Improving the corporate governance of AGI labs

### My approach to research (“how”)
- Focus on impact (“keep your eyes on the price”)
- Make concrete recommendations
- Apply best practices from other industries to AI
- Be epistemically honest
- Be collaborative

### My Ongoing research projects (“what”):
- Responsible AGI labs
- AGI labs need an internal audit function
- Risk assessment at AGI labs (w/ Leonie Koessler)
- AI ethics boards (w/ Anka Reuel, Alexis Carlier)
- Board governance at AGI labs (w/ Nikhil Mulani, John Bridge)

---

# Publications

- **Defining the scope of AI regulations** <br>
Jonas Schuett <br>
2023, March 3 <br>
Law, Innovation and Technology <br>
[https://doi.org/10.1080/17579961.2023.2184135](https://doi.org/10.1080/17579961.2023.2184135)

- **Auditing large language models: A three-layered approach** <br>
Jakob Mökander, Jonas Schuett, Hannah R. Kirk, Luciano Floridi <br>
2023, February 16 <br>
arXiv:2302.08500 <br>
[https://arxiv.org/abs/2302.08500](https://arxiv.org/abs/2302.08500)

- **Risk management in the Artificial Intelligence Act** <br>
Jonas Schuett <br>
2023, February 8 <br>
European Journal of Risk Regulation <br>
[https://doi.org/10.1017/err.2023.1](https://doi.org/10.1017/err.2023.1)

- **Three lines of defense against risks from AI** <br>
Jonas Schuett <br>
2022, December 16 <br>
arXiv:2212.08364 <br>
[https://arxiv.org/abs/2212.08364](https://arxiv.org/abs/2212.08364)

- **Corporate governance of artificial intelligence in the public interest** <br>
Peter Cihon, Jonas Schuett, Seth D. Baum <br>
2021, July 5 <br>
Information <br>
[https://doi.org/10.3390/info12070275](https://doi.org/10.3390/info12070275)

- **AI certification: Advancing ethical practice by reducing information asymmetries** <br>
Peter Cihon, Moritz J. Kleinaltenkamp, Jonas Schuett, Seth D. Baum <br>
2021, May 10 <br>
IEEE Transactions on Technology and Society <br>
[https://doi.org/10.1109/TTS.2021.3077595](https://doi.org/10.1109/TTS.2021.3077595)

---

# Contact
Find my research:
- [ORCID](https://orcid.org/0000-0001-7154-5049)
- [Google Scholar](https://scholar.google.com/citations?user=iZXltDgAAAAJ&hl=en&oi=ao)
- [SSRN](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=3705327)

Contact:
- [https://twitter.com/jonasschuett](https://twitter.com/jonasschuett)
- [https://www.linkedin.com/in/jonasschuett](https://www.linkedin.com/in/jonasschuett)
- [jonas.schuett@governance.ai](mailto:jonas.schuett@governance.ai)
